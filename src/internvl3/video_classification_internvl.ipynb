{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmK_goMP07c0",
        "outputId": "2cd959b3-edba-491b-b5e4-31df4ffb0428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==2.1.0 torchvision==0.16.0 --upgrade --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6aYjE8VRSS_",
        "outputId": "ea711266-c2cd-4e62-83c0-9d3858048b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKanvO6E0en7",
        "outputId": "1ed6f278-a9be-429c-ac89-e89f1703fab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.40.0\n",
            "  Using cached transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n",
            "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (2025.4.26)\n",
            "Using cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
            "Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.1\n",
            "    Uninstalling tokenizers-0.15.1:\n",
            "      Successfully uninstalled tokenizers-0.15.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.37.2\n",
            "    Uninstalling transformers-4.37.2:\n",
            "      Successfully uninstalled transformers-4.37.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.0\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (14.4.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.2.1)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from decord) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (2.7.4.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.11/dist-packages (0.16.9)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed) (0.6.1)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.11.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.11.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed) (4.67.1)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed) (12.575.51)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepspeed) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.40.0\n",
        "!pip install av\n",
        "!pip install imageio\n",
        "!pip install decord\n",
        "!pip install opencv-python\n",
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade deepspeed bitsandbytes\n",
        "\n",
        "!pip install -U huggingface_hub\n",
        "\n",
        "!pip install peft==0.10.0\n",
        "\n",
        "!pip install accelerate==0.28.0"
      ],
      "metadata": {
        "id": "rek8erbiR4_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4 --no-cache-dir --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TDRfahEWnht",
        "outputId": "92c1cb71-3397-418e-a245-8fdc9a43f1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m330.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tPkDVL-7X_O",
        "outputId": "81a815b0-9a64-4d53-c203-e39c130d6cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "++++++++++++++++++ BUG REPORT INFORMATION ++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++ OTHER +++++++++++++++++++++++++++\n",
            "CUDA specs: CUDASpecs(highest_compute_capability=(8, 0), cuda_version_string='124', cuda_version_tuple=(12, 4))\n",
            "PyTorch settings found: CUDA_VERSION=124, Highest Compute Capability: (8, 0).\n",
            "To manually override the PyTorch CUDA version please see: https://github.com/TimDettmers/bitsandbytes/blob/main/docs/source/nonpytorchcuda.mdx\n",
            "The directory listed in your path is found to be non-existent: /sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events\n",
            "The directory listed in your path is found to be non-existent: //172.28.0.1\n",
            "The directory listed in your path is found to be non-existent: 8013\n",
            "The directory listed in your path is found to be non-existent: //colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-pspzlcwunaon --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true \n",
            "The directory listed in your path is found to be non-existent: /datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages\n",
            "The directory listed in your path is found to be non-existent: /env/python\n",
            "The directory listed in your path is found to be non-existent: //matplotlib_inline.backend_inline\n",
            "The directory listed in your path is found to be non-existent: //mp.kaggle.net/models/openapi\n",
            "CUDA SETUP: WARNING! CUDA runtime files not found in any environmental path.\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "++++++++++++++++++++++ DEBUG INFO END ++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "Checking that the library is importable and CUDA is callable...\n",
            "SUCCESS!\n",
            "Installation was successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OpenGVLab/InternVL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dzjaipd1-5w",
        "outputId": "ce5031e9-4e67-4ad9-ef84-04154bbd442a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'InternVL'...\n",
            "remote: Enumerating objects: 3549, done.\u001b[K\n",
            "remote: Counting objects: 100% (430/430), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 3549 (delta 361), reused 286 (delta 286), pack-reused 3119 (from 4)\u001b[K\n",
            "Receiving objects: 100% (3549/3549), 39.51 MiB | 16.36 MiB/s, done.\n",
            "Resolving deltas: 100% (2120/2120), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r /content/InternVL/requirements/internvl_chat.txt"
      ],
      "metadata": {
        "id": "yQg37vT56aGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from decord import VideoReader, cpu\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "# model setting\n",
        "model_path = \"OpenGVLab/InternVL2_5-2B\" # 'OpenGVLab/InternVideo2_5_Chat_8B'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda().to(torch.bfloat16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kqG2-N2W-I",
        "outputId": "75e5906a-d64f-4ca6-cf01-da9c0f0132f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def build_transform(input_size):\n",
        "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
        "    transform = T.Compose([T.Lambda(lambda img: img.convert(\"RGB\") if img.mode != \"RGB\" else img), T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC), T.ToTensor(), T.Normalize(mean=MEAN, std=STD)])\n",
        "    return transform\n",
        "\n",
        "\n",
        "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
        "    best_ratio_diff = float(\"inf\")\n",
        "    best_ratio = (1, 1)\n",
        "    area = width * height\n",
        "    for ratio in target_ratios:\n",
        "        target_aspect_ratio = ratio[0] / ratio[1]\n",
        "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
        "        if ratio_diff < best_ratio_diff:\n",
        "            best_ratio_diff = ratio_diff\n",
        "            best_ratio = ratio\n",
        "        elif ratio_diff == best_ratio_diff:\n",
        "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
        "                best_ratio = ratio\n",
        "    return best_ratio\n",
        "\n",
        "\n",
        "def dynamic_preprocess(image, min_num=1, max_num=6, image_size=448, use_thumbnail=False):\n",
        "    orig_width, orig_height = image.size\n",
        "    aspect_ratio = orig_width / orig_height\n",
        "\n",
        "    # calculate the existing image aspect ratio\n",
        "    target_ratios = set((i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if i * j <= max_num and i * j >= min_num)\n",
        "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
        "\n",
        "    # find the closest aspect ratio to the target\n",
        "    target_aspect_ratio = find_closest_aspect_ratio(aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
        "\n",
        "    # calculate the target width and height\n",
        "    target_width = image_size * target_aspect_ratio[0]\n",
        "    target_height = image_size * target_aspect_ratio[1]\n",
        "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
        "\n",
        "    # resize the image\n",
        "    resized_img = image.resize((target_width, target_height))\n",
        "    processed_images = []\n",
        "    for i in range(blocks):\n",
        "        box = ((i % (target_width // image_size)) * image_size, (i // (target_width // image_size)) * image_size, ((i % (target_width // image_size)) + 1) * image_size, ((i // (target_width // image_size)) + 1) * image_size)\n",
        "        # split the image\n",
        "        split_img = resized_img.crop(box)\n",
        "        processed_images.append(split_img)\n",
        "    assert len(processed_images) == blocks\n",
        "    if use_thumbnail and len(processed_images) != 1:\n",
        "        thumbnail_img = image.resize((image_size, image_size))\n",
        "        processed_images.append(thumbnail_img)\n",
        "    return processed_images\n",
        "\n",
        "\n",
        "def load_image(image, input_size=448, max_num=6):\n",
        "    transform = build_transform(input_size=input_size)\n",
        "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
        "    pixel_values = [transform(image) for image in images]\n",
        "    pixel_values = torch.stack(pixel_values)\n",
        "    return pixel_values\n",
        "\n",
        "\n",
        "def get_index(bound, fps, max_frame, first_idx=0, num_segments=32):\n",
        "    if bound:\n",
        "        start, end = bound[0], bound[1]\n",
        "    else:\n",
        "        start, end = -100000, 100000\n",
        "    start_idx = max(first_idx, round(start * fps))\n",
        "    end_idx = min(round(end * fps), max_frame)\n",
        "    seg_size = float(end_idx - start_idx) / num_segments\n",
        "    frame_indices = np.array([int(start_idx + (seg_size / 2) + np.round(seg_size * idx)) for idx in range(num_segments)])\n",
        "    return frame_indices\n",
        "\n",
        "def get_num_frames_by_duration(duration):\n",
        "        local_num_frames = 4\n",
        "        num_segments = int(duration // local_num_frames)\n",
        "        if num_segments == 0:\n",
        "            num_frames = local_num_frames\n",
        "        else:\n",
        "            num_frames = local_num_frames * num_segments\n",
        "\n",
        "        num_frames = min(512, num_frames)\n",
        "        num_frames = max(128, num_frames)\n",
        "\n",
        "        return num_frames\n",
        "\n",
        "def load_video(video_path, bound=None, input_size=448, max_num=1, num_segments=32, get_frame_by_duration = False):\n",
        "    vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
        "    max_frame = len(vr) - 1\n",
        "    fps = float(vr.get_avg_fps())\n",
        "\n",
        "    pixel_values_list, num_patches_list = [], []\n",
        "    transform = build_transform(input_size=input_size)\n",
        "    if get_frame_by_duration:\n",
        "        duration = max_frame / fps\n",
        "        num_segments = get_num_frames_by_duration(duration)\n",
        "    frame_indices = get_index(bound, fps, max_frame, first_idx=0, num_segments=num_segments)\n",
        "    for frame_index in frame_indices:\n",
        "        img = Image.fromarray(vr[frame_index].asnumpy()).convert(\"RGB\")\n",
        "        img = dynamic_preprocess(img, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
        "        pixel_values = [transform(tile) for tile in img]\n",
        "        pixel_values = torch.stack(pixel_values)\n",
        "        num_patches_list.append(pixel_values.shape[0])\n",
        "        pixel_values_list.append(pixel_values)\n",
        "    pixel_values = torch.cat(pixel_values_list)\n",
        "    return pixel_values, num_patches_list\n",
        "\n"
      ],
      "metadata": {
        "id": "Q6XRlPFI0nUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation setting\n",
        "max_num_frames = 512\n",
        "generation_config = dict(\n",
        "    do_sample=False,\n",
        "    temperature=0.0,\n",
        "    max_new_tokens=1024,\n",
        "    top_p=0.1,\n",
        "    num_beams=1\n",
        ")\n",
        "video_path = \"/content/drive/MyDrive/deception_detection/train/trial_lie_001_000.mp4\"\n",
        "num_segments=128\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  torch.cuda.empty_cache()\n",
        "  import gc\n",
        "  gc.collect()\n",
        "  pixel_values, num_patches_list = load_video(video_path, num_segments=num_segments, max_num=1, get_frame_by_duration=False)\n",
        "  print(len(num_patches_list))\n",
        "  pixel_values = pixel_values.to(torch.bfloat16).to(model.device)\n",
        "  video_prefix = \"\".join([f\"Frame{i+1}: <image>\\n\" for i in range(len(num_patches_list))])\n",
        "  # single-turn conversation\n",
        "  question1 = \"Describe this video in detail.\"\n",
        "  question = video_prefix + question1\n",
        "  output1, chat_history = model.chat(tokenizer, pixel_values, question, generation_config, num_patches_list=num_patches_list, history=None, return_history=True)\n",
        "  print(output1)\n",
        "  del output1\n",
        "  torch.cuda.empty_cache()\n",
        "  import gc\n",
        "  gc.collect()\n",
        "  # # multi-turn conversation\n",
        "  question2 = \"How many people appear in the video?\"\n",
        "  output2, chat_history = model.chat(tokenizer, pixel_values, question, generation_config, num_patches_list=num_patches_list, history=chat_history, return_history=True)\n",
        "\n",
        "  print(output2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxfXc7yL2RC7",
        "outputId": "8b1e400b-a7af-4a7b-d9c3-f0b98ca4b40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "The scene takes place in a courtroom setting, indicated by the presence of a judge's bench and the American flag in the background. The subject, a woman, is dressed in a pink blazer over a white blouse, suggesting a formal or professional occasion. She is seated behind a wooden bench, which is typical of a courtroom. The lighting is bright and even, likely from overhead fluorescent lights, which is common in institutional settings. The environment appears to be quiet and controlled, with no other individuals or movement visible in the frame. The colors are muted with the exception of the woman's pink blazer, which stands out against the more subdued tones of the courtroom. The woman's posture is upright and composed, indicating she is either listening intently or waiting for her turn to speak.\n",
            "The scene takes place in a courtroom setting, indicated by the presence of a judge's bench and the American flag in the background. The subject, a woman, is dressed in a pink blazer over a white blouse, suggesting a formal or professional occasion. She is seated behind a wooden bench, which is typical of a courtroom. The lighting is bright and even, likely from overhead fluorescent lights, which is common in institutional settings. The environment appears to be quiet and controlled, with no other individuals or movement visible in the frame. The colors are muted with the exception of the woman's pink blazer, which stands out against the more subdued tones of the courtroom. The woman's posture is upright and composed, indicating she is either listening intently or waiting for her turn to speak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "CItVVmvtSTj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict\n",
        "import random\n",
        "\n",
        "\n",
        "def build_internvl_video_jsonl(\n",
        "    video_dir: str,\n",
        "    output_jsonl_path: str,\n",
        "    prompt_text: str = \"Predict if the person in this video is lying (output \\\"lie\\\") or telling the truth (output \\\"truth\\\").\"\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Converts a folder of video clips into the InternVL chat data format (JSONL).\n",
        "\n",
        "    Args:\n",
        "        video_dir (str): Directory containing .mp4 video files (named with 'lie' or 'truth' in the name).\n",
        "        output_jsonl_path (str): File path to save the resulting JSONL dataset.\n",
        "        prompt_text (str): Text prompt for the human in each conversation.\n",
        "    \"\"\"\n",
        "    data_entries: List[Dict] = []\n",
        "    video_filenames = sorted(os.listdir(video_dir))\n",
        "    video_id = 0\n",
        "\n",
        "    for fname in video_filenames:\n",
        "        if not fname.endswith(\".mp4\"):\n",
        "            continue\n",
        "\n",
        "        parts = fname.split(\"_\")\n",
        "        if len(parts) < 3:\n",
        "            print(f\"Skipping malformed filename: {fname}\")\n",
        "            continue\n",
        "\n",
        "        label_str = parts[1].lower()\n",
        "        if label_str not in [\"lie\", \"truth\"]:\n",
        "            print(f\"Unknown label in filename: {fname}\")\n",
        "            continue\n",
        "\n",
        "        label = label_str  # 'lie' or 'truth'\n",
        "        video_path = fname  # relative path for InternVL\n",
        "\n",
        "        entry = {\n",
        "            \"id\": video_id,\n",
        "            \"video\": video_path,\n",
        "            \"conversations\": [\n",
        "                {\n",
        "                    \"from\": \"human\",\n",
        "                    \"value\": f\"<video>\\n{prompt_text}\"\n",
        "                },\n",
        "                {\n",
        "                    \"from\": \"gpt\",\n",
        "                    \"value\": label\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        data_entries.append(entry)\n",
        "        video_id += 1\n",
        "\n",
        "    random.shuffle(data_entries)\n",
        "    # Save to JSONL\n",
        "    with open(output_jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in data_entries:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    print(f\"Saved {len(data_entries)} entries to {output_jsonl_path}\")\n",
        "\n",
        "\n",
        "# Example usage (adjust paths in Colab!)\n",
        "ROOT_DIR = \"/content/drive/MyDrive/deception_detection/train\"\n",
        "OUTPUT_JSONL = \"/content/drive/MyDrive/deception_detection/internvl_train.jsonl\"\n",
        "\n",
        "build_internvl_video_jsonl(\n",
        "    video_dir=ROOT_DIR,\n",
        "    output_jsonl_path=OUTPUT_JSONL\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRO7NK6L2Dmb",
        "outputId": "7708cb09-c16f-4279-a3ef-392b8857264d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 601 entries to /content/drive/MyDrive/deception_detection/internvl_train.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "meta = {\n",
        "    \"deception_train_set\": {\n",
        "        \"root\": \"/content/drive/MyDrive/deception_detection/train/\",\n",
        "        \"annotation\": \"/content/drive/MyDrive/deception_detection/internvl_train.jsonl\",\n",
        "        \"data_augment\": False,\n",
        "        \"max_dynamic_patch\": 4,\n",
        "        \"repeat_time\": 1,\n",
        "        \"length\": 500  # <- replace with actual count if known\n",
        "    }\n",
        "}\n",
        "os.makedirs(\"/content/drive/MyDrive/deception_detection\", exist_ok=True)\n",
        "\n",
        "meta_path = \"/content/drive/MyDrive/deception_detection/meta_train.json\"\n",
        "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(\"✅ Meta file created:\", meta_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZXqmfgQ2F1O",
        "outputId": "025daee1-71e8-464a-a633-dfb870cab63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Meta file created: /content/drive/MyDrive/deception_detection/meta_train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import HfApi, HfFolder, snapshot_download, create_repo, upload_folder\n",
        "\n",
        "# Parameters\n",
        "GPUS = 1\n",
        "BATCH_SIZE = 8\n",
        "PER_DEVICE_BATCH_SIZE = 2\n",
        "GRADIENT_ACC = BATCH_SIZE // PER_DEVICE_BATCH_SIZE // GPUS\n",
        "MASTER_PORT = 34229\n",
        "\n",
        "# Save to Google Drive\n",
        "HF_MODEL_NAME = \"InternVL2_5-2B-deception-finetuned\"  # \"internvideo2_5-8b-deception-finetuned\"\n",
        "DRIVE_OUTPUT_DIR = f\"/content/drive/MyDrive/deception_detection/{HF_MODEL_NAME}\"\n",
        "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Also save locally for training compatibility\n",
        "LOCAL_OUTPUT_DIR = f\"work_dirs/internvl_chat_v2_5/{HF_MODEL_NAME}\"\n",
        "os.makedirs(LOCAL_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Export environment\n",
        "os.environ['PYTHONPATH'] = f\"{os.environ.get('PYTHONPATH', '')}:{os.getcwd()}\"\n",
        "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "#os.environ['MASTER_PORT'] = str(MASTER_PORT)\n",
        "os.environ[\"PYTHONPATH\"] += \":/content/InternVL/internvl_chat\"\n",
        "os.environ[\"LAUNCHER\"] = \"pytorch\"\n",
        "\n",
        "!export LD_LIBRARY_PATH=/usr/lib64-nvidia:$LD_LIBRARY_PATH\n",
        "\n",
        "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/lib64-nvidia:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n"
      ],
      "metadata": {
        "id": "kBkix4CP2IKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMn2ZtQ968Dv",
        "outputId": "cdf050bc-7256-4625-c7cd-a9c367c8e767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 24 13:11:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             47W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install decord==0.6.0 --no-cache-dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riuooDuwdG51",
        "outputId": "7d00858c-5f67-4f0e-c427-e9a8e91a7b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: decord==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from decord==0.6.0) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_META_PATH = \"/content/drive/MyDrive/deception_detection/meta_train.json\"\n",
        "TRAIN_SCRIPT_PATH = \"InternVL/internvl_chat/internvl/train/internvl_chat_finetune.py\"\n",
        "DEEPSPEED_CONFIG = \"InternVL/internvl_chat/zero_stage1_config.json\"\n",
        "\n",
        "!CUDA_LAUNCH_BLOCKING=1 TORCH_DISTRIBUTED_DEBUG=DETAIL \\\n",
        "torchrun --nproc_per_node=1 \\\n",
        "  \"InternVL/internvl_chat/internvl/train/internvl_chat_finetune.py\" \\\n",
        "  --model_name_or_path \"OpenGVLab/InternVL2_5-2B\" \\\n",
        "  --conv_style \"internvl2_5\" \\\n",
        "  --use_fast_tokenizer False \\\n",
        "  --output_dir \"/content/drive/MyDrive/deception_detection/internvl2.5-2b-deception-finetuned\" \\\n",
        "  --meta_path \"/content/drive/MyDrive/deception_detection/meta_train.json\" \\\n",
        "  --overwrite_output_dir True \\\n",
        "  --force_image_size 224 \\\n",
        "  --max_dynamic_patch 4 \\\n",
        "  --down_sample_ratio 0.5 \\\n",
        "  --drop_path_rate 0.0 \\\n",
        "  --freeze_llm True \\\n",
        "  --freeze_mlp True \\\n",
        "  --freeze_backbone True \\\n",
        "  --use_llm_lora 16 \\\n",
        "  --vision_select_layer -1 \\\n",
        "  --dataloader_num_workers 2 \\\n",
        "  --fp16 True \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --per_device_train_batch_size 1 \\\n",
        "  --gradient_accumulation_steps 4 \\\n",
        "  --evaluation_strategy \"no\" \\\n",
        "  --save_strategy \"steps\" \\\n",
        "  --save_steps 200 \\\n",
        "  --save_total_limit 1 \\\n",
        "  --learning_rate 4e-5 \\\n",
        "  --weight_decay 0.05 \\\n",
        "  --warmup_ratio 0.03 \\\n",
        "  --lr_scheduler_type \"cosine\" \\\n",
        "  --logging_steps 1 \\\n",
        "  --max_seq_length 8192 \\\n",
        "  --do_train True \\\n",
        "  --grad_checkpoint True \\\n",
        "  --group_by_length True \\\n",
        "  --dynamic_image_size True \\\n",
        "  --use_thumbnail True \\\n",
        "  --ps_version \"v2\" \\\n",
        "  --deepspeed \"InternVL/internvl_chat/zero_stage1_config.json\" \\\n",
        "  --report_to \"tensorboard\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VYV2y0RR2Mu_",
        "outputId": "b68e26f8-564b-4225-e214-5f6cd4b00bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-24 13:58:45,576] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-05-24 13:58:50.099629: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748095130.121867   27789 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748095130.128646   27789 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "[2025-05-24 13:58:52,729] [INFO] [comm.py:669:init_distributed] cdb=None\n",
            "[2025-05-24 13:58:52,729] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "05/24/2025 13:58:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
            "05/24/2025 13:58:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=2,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=InternVL/internvl_chat/zero_stage1_config.json,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=4e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/deception_detection/internvl2.5-2b-deception-finetuned/runs/May24_13-58-52_c616d2606d92,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=1.0,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/deception_detection/internvl2.5-2b-deception-finetuned,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/deception_detection/internvl2.5-2b-deception-finetuned,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=200,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.05,\n",
            ")\n",
            "05/24/2025 13:58:52 - INFO - __main__ - Loading Tokenizer: OpenGVLab/InternVL2_5-2B\n",
            "[INFO|tokenization_utils_base.py:2087] 2025-05-24 13:58:53,288 >> loading file ./tokenizer.model from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/./tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2087] 2025-05-24 13:58:53,288 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2087] 2025-05-24 13:58:53,288 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2087] 2025-05-24 13:58:53,288 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2087] 2025-05-24 13:58:53,288 >> loading file tokenizer.json from cache at None\n",
            "[WARNING|logging.py:314] 2025-05-24 13:58:53,457 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "05/24/2025 13:58:53 - INFO - __main__ - Loading InternVLChatModel...\n",
            "[INFO|configuration_utils.py:726] 2025-05-24 13:58:53,832 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/config.json\n",
            "[INFO|configuration_utils.py:789] 2025-05-24 13:58:53,834 >> Model config InternVLChatConfig {\n",
            "  \"_commit_hash\": \"573169ee54df216786bb9a189e9a32a060a008cf\",\n",
            "  \"architectures\": [\n",
            "    \"InternVLChatModel\"\n",
            "  ],\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"OpenGVLab/InternVL2_5-2B--configuration_internvl_chat.InternVLChatConfig\",\n",
            "    \"AutoModel\": \"OpenGVLab/InternVL2_5-2B--modeling_internvl_chat.InternVLChatModel\",\n",
            "    \"AutoModelForCausalLM\": \"OpenGVLab/InternVL2_5-2B--modeling_internvl_chat.InternVLChatModel\"\n",
            "  },\n",
            "  \"downsample_ratio\": 0.5,\n",
            "  \"dynamic_image_size\": true,\n",
            "  \"force_image_size\": 448,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"llm_config\": {\n",
            "    \"_name_or_path\": \"internlm/internlm2_5-1_8b-chat\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"InternLM2ForCausalLM\"\n",
            "    ],\n",
            "    \"attn_implementation\": \"flash_attention_2\",\n",
            "    \"auto_map\": {\n",
            "      \"AutoConfig\": \"configuration_internlm2.InternLM2Config\",\n",
            "      \"AutoModel\": \"modeling_internlm2.InternLM2ForCausalLM\",\n",
            "      \"AutoModelForCausalLM\": \"modeling_internlm2.InternLM2ForCausalLM\",\n",
            "      \"AutoModelForSequenceClassification\": \"modeling_internlm2.InternLM2ForSequenceClassification\"\n",
            "    },\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bias\": false,\n",
            "    \"bos_token_id\": 1,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 2048,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 8192,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 32768,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"internlm2\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"num_key_value_heads\": 8,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 2,\n",
            "    \"prefix\": null,\n",
            "    \"pretraining_tp\": 1,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"rms_norm_eps\": 1e-05,\n",
            "    \"rope_scaling\": {\n",
            "      \"factor\": 2.0,\n",
            "      \"type\": \"dynamic\"\n",
            "    },\n",
            "    \"rope_theta\": 1000000,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": false,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.40.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": true,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 92553\n",
            "  },\n",
            "  \"max_dynamic_patch\": 12,\n",
            "  \"min_dynamic_patch\": 1,\n",
            "  \"model_type\": \"internvl_chat\",\n",
            "  \"pad2square\": false,\n",
            "  \"ps_version\": \"v2\",\n",
            "  \"select_layer\": -1,\n",
            "  \"template\": \"internvl2_5\",\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_backbone_lora\": 0,\n",
            "  \"use_llm_lora\": 0,\n",
            "  \"use_thumbnail\": true,\n",
            "  \"vision_config\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"InternVisionModel\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"drop_path_rate\": 0.0,\n",
            "    \"dropout\": 0.0,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_size\": 1024,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"image_size\": 448,\n",
            "    \"initializer_factor\": 1.0,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 4096,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-06,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"intern_vit_6b\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"norm_type\": \"layer_norm\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_channels\": 3,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": null,\n",
            "    \"patch_size\": 14,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"qk_normalization\": false,\n",
            "    \"qkv_bias\": true,\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.40.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": true,\n",
            "    \"use_flash_attn\": true\n",
            "  }\n",
            "}\n",
            "\n",
            "05/24/2025 13:58:53 - INFO - __main__ - Using flash_attention_2 for InternLM\n",
            "[INFO|modeling_utils.py:3429] 2025-05-24 13:58:53,834 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/model.safetensors\n",
            "[INFO|modeling_utils.py:1494] 2025-05-24 13:58:53,853 >> Instantiating InternVLChatModel model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:928] 2025-05-24 13:58:53,855 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|configuration_utils.py:928] 2025-05-24 13:58:53,910 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 2\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4170] 2025-05-24 13:58:54,969 >> All model checkpoint weights were used when initializing InternVLChatModel.\n",
            "\n",
            "[INFO|modeling_utils.py:4178] 2025-05-24 13:58:54,969 >> All the weights of InternVLChatModel were initialized from the model checkpoint at OpenGVLab/InternVL2_5-2B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLChatModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:883] 2025-05-24 13:58:55,211 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-2B/snapshots/573169ee54df216786bb9a189e9a32a060a008cf/generation_config.json\n",
            "[INFO|configuration_utils.py:928] 2025-05-24 13:58:55,212 >> Generate config GenerationConfig {\n",
            "  \"eos_token_id\": [\n",
            "    92542,\n",
            "    92543\n",
            "  ]\n",
            "}\n",
            "\n",
            "05/24/2025 13:58:55 - INFO - __main__ - Finished\n",
            "05/24/2025 13:58:55 - INFO - __main__ - model.config.force_image_size: 448\n",
            "05/24/2025 13:58:55 - INFO - __main__ - data_args.force_image_size: 224\n",
            "05/24/2025 13:58:55 - INFO - __main__ - model.config.vision_config.image_size: 448\n",
            "05/24/2025 13:58:55 - INFO - __main__ - Resizing position embedding from 448 to 224...\n",
            "05/24/2025 13:58:55 - INFO - __main__ - max_dynamic_patch is set to 4 according to the meta file\n",
            "05/24/2025 13:58:55 - INFO - __main__ - [Dataset] num_image_token: 64\n",
            "05/24/2025 13:58:55 - INFO - __main__ - [Dataset] dynamic_image_size: True\n",
            "05/24/2025 13:58:55 - INFO - __main__ - [Dataset] use_thumbnail: True\n",
            "05/24/2025 13:58:55 - INFO - __main__ - [Dataset] min_dynamic_patch: 1, max_dynamic_patch: 4\n",
            "05/24/2025 13:58:55 - INFO - __main__ - Formatting inputs...Skip in lazy mode\n",
            "05/24/2025 13:58:55 - INFO - __main__ - Add dataset: deception_train_set with length: 601\n",
            "trainable params: 15,728,640 || all params: 1,904,875,520 || trainable%: 0.8257043483870274\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w2.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wqkv.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wqkv.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wo.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wo.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w1.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w1.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w3.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w3.lora_B.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w2.lora_A.default.weight\n",
            "05/24/2025 13:58:55 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w2.lora_B.default.weight\n",
            "[INFO|trainer.py:626] 2025-05-24 13:58:55,660 >> Using auto half precision backend\n",
            "[2025-05-24 13:58:56,029] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.9, git-hash=unknown, git-branch=unknown\n",
            "[2025-05-24 13:58:56,029] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 1\n",
            "[2025-05-24 13:58:58,682] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.03032374382019043 seconds\n",
            "[2025-05-24 13:58:58,714] [INFO] [logging.py:107:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
            "[2025-05-24 13:58:58,714] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2025-05-24 13:58:58,734] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2025-05-24 13:58:58,734] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2025-05-24 13:58:58,734] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2025-05-24 13:58:58,734] [INFO] [stage_1_and_2.py:150:__init__] Reduce bucket size 1000000000\n",
            "[2025-05-24 13:58:58,734] [INFO] [stage_1_and_2.py:151:__init__] Allgather bucket size 1000000000\n",
            "[2025-05-24 13:58:58,734] [INFO] [stage_1_and_2.py:152:__init__] CPU Offload: False\n",
            "[2025-05-24 13:58:58,734] [INFO] [stage_1_and_2.py:153:__init__] Round robin gradient partitioning: False\n",
            "[2025-05-24 13:58:59,143] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
            "[2025-05-24 13:58:59,144] [INFO] [utils.py:782:see_memory_usage] MA 4.57 GB         Max_MA 4.6 GB         CA 4.8 GB         Max_CA 5 GB \n",
            "[2025-05-24 13:58:59,144] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 7.61 GB, percent = 9.1%\n",
            "[2025-05-24 13:58:59,504] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
            "[2025-05-24 13:58:59,504] [INFO] [utils.py:782:see_memory_usage] MA 4.57 GB         Max_MA 4.63 GB         CA 4.86 GB         Max_CA 5 GB \n",
            "[2025-05-24 13:58:59,505] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 7.61 GB, percent = 9.1%\n",
            "[2025-05-24 13:58:59,505] [INFO] [stage_1_and_2.py:557:__init__] optimizer state initialized\n",
            "[2025-05-24 13:58:59,861] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2025-05-24 13:58:59,862] [INFO] [utils.py:782:see_memory_usage] MA 4.57 GB         Max_MA 4.57 GB         CA 4.86 GB         Max_CA 5 GB \n",
            "[2025-05-24 13:58:59,862] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 7.61 GB, percent = 9.1%\n",
            "[2025-05-24 13:58:59,867] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
            "[2025-05-24 13:58:59,867] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using client callable to create LR scheduler\n",
            "[2025-05-24 13:58:59,867] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f0c22bcf750>\n",
            "[2025-05-24 13:58:59,867] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.999]]\n",
            "[2025-05-24 13:58:59,872] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:\n",
            "[2025-05-24 13:58:59,872] [INFO] [config.py:1007:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2025-05-24 13:58:59,872] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
            "[2025-05-24 13:58:59,872] [INFO] [config.py:1007:print]   amp_enabled .................. False\n",
            "[2025-05-24 13:58:59,872] [INFO] [config.py:1007:print]   amp_params ................... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   bfloat16_enabled ............. False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0c251656d0>\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   communication_data_type ...... None\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   disable_allgather ............ False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   dump_state ................... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01\n",
            "[2025-05-24 13:58:59,873] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   elasticity_enabled ........... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   fp16_auto_cast ............... True\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   fp16_enabled ................. True\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   global_rank .................. 0\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 4\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   graph_harvesting ............. False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   loss_scale ................... 0\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   memory_breakdown ............. False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   mics_shard_size .............. -1\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   optimizer_name ............... adamw\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   optimizer_params ............. {'lr': 4e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.05}\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   pld_enabled .................. False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   pld_params ................... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   prescale_gradients ........... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   scheduler_name ............... None\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   scheduler_params ............. None\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   sparse_attention ............. None\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   steps_per_print .............. inf\n",
            "[2025-05-24 13:58:59,874] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   train_batch_size ............. 4\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  1\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   use_node_local_storage ....... False\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... True\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   weight_quantization_config ... None\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   world_size ................... 1\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1000000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1000000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   zero_enabled ................. True\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 1\n",
            "[2025-05-24 13:58:59,875] [INFO] [config.py:993:print_user_config]   json = {\n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 1.000000e+09, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 1.000000e+09, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"auto_cast\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"initial_scale_power\": 32, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"bf16\": {\n",
            "        \"enabled\": false\n",
            "    }, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"AdamW\", \n",
            "        \"params\": {\n",
            "            \"lr\": 4e-05, \n",
            "            \"betas\": [0.9, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 0.05\n",
            "        }\n",
            "    }, \n",
            "    \"gradient_accumulation_steps\": 4, \n",
            "    \"gradient_clipping\": 1.0, \n",
            "    \"steps_per_print\": inf, \n",
            "    \"train_batch_size\": 4, \n",
            "    \"train_micro_batch_size_per_gpu\": 1, \n",
            "    \"wall_clock_breakdown\": true\n",
            "}\n",
            "[INFO|trainer.py:2048] 2025-05-24 13:58:59,875 >> ***** Running training *****\n",
            "[INFO|trainer.py:2049] 2025-05-24 13:58:59,875 >>   Num examples = 601\n",
            "[INFO|trainer.py:2050] 2025-05-24 13:58:59,875 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:2051] 2025-05-24 13:58:59,875 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2054] 2025-05-24 13:58:59,875 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:2055] 2025-05-24 13:58:59,875 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2056] 2025-05-24 13:58:59,875 >>   Total optimization steps = 150\n",
            "[INFO|trainer.py:2057] 2025-05-24 13:58:59,879 >>   Number of trainable parameters = 15,728,640\n",
            "  0% 0/150 [00:00<?, ?it/s][2025-05-24 13:59:03,365] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-05-24 13:59:07.811485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748095147.832555   27997 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748095147.839188   27997 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "[2025-05-24 13:59:13,950] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-05-24 13:59:18.347845: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748095158.368893   28155 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748095158.375314   28155 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:24,585] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 725.51 | bwd_microstep: 508.46 | bwd_inner_microstep: 504.45 | bwd_allreduce_microstep: 0.08 | step_microstep: 0.06\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:25,348] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 336.95 | bwd_microstep: 404.70 | bwd_inner_microstep: 404.31 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.05\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:27,462] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 344.60 | bwd_microstep: 378.36 | bwd_inner_microstep: 377.97 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.05\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:28,328] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.05 | optimizer_gradients: 10.97 | optimizer_step: 3.78\n",
            "[2025-05-24 13:59:28,328] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 330.56 | bwd_microstep: 410.73 | bwd_inner_microstep: 398.23 | bwd_allreduce_microstep: 12.15 | step_microstep: 105.89\n",
            "[2025-05-24 13:59:28,329] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd: 1737.63 | bwd: 1702.24 | bwd_inner: 1684.99 | bwd_allreduce: 12.35 | step: 106.05\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\n",
            "  1% 1/150 [00:28<1:10:38, 28.44s/it]dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:29,399] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 344.12 | bwd_microstep: 380.48 | bwd_inner_microstep: 380.06 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.05\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:30,141] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 338.71 | bwd_microstep: 383.66 | bwd_inner_microstep: 383.29 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.05\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:30,899] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 335.03 | bwd_microstep: 404.50 | bwd_inner_microstep: 404.14 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.05\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:31,754] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.05 | optimizer_gradients: 1.43 | optimizer_step: 0.73\n",
            "[2025-05-24 13:59:31,754] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 340.37 | bwd_microstep: 426.67 | bwd_inner_microstep: 414.38 | bwd_allreduce_microstep: 11.96 | step_microstep: 68.22\n",
            "[2025-05-24 13:59:31,755] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd: 1358.24 | bwd: 1595.31 | bwd_inner: 1581.96 | bwd_allreduce: 12.15 | step: 68.38\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}\n",
            "  1% 2/150 [00:31<33:51, 13.73s/it]dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:32,500] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 338.68 | bwd_microstep: 381.62 | bwd_inner_microstep: 381.28 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.10\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:34,506] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 330.93 | bwd_microstep: 368.30 | bwd_inner_microstep: 367.94 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.09\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:35,240] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 333.16 | bwd_microstep: 381.61 | bwd_inner_microstep: 381.21 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.09\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:36,431] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.05 | optimizer_gradients: 1.43 | optimizer_step: 0.75\n",
            "[2025-05-24 13:59:36,432] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 332.63 | bwd_microstep: 421.76 | bwd_inner_microstep: 405.63 | bwd_allreduce_microstep: 15.78 | step_microstep: 72.06\n",
            "[2025-05-24 13:59:36,432] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd: 1335.40 | bwd: 1553.28 | bwd_inner: 1536.14 | bwd_allreduce: 15.95 | step: 72.34\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.4e-05, 'epoch': 0.02}\n",
            "  2% 3/150 [00:36<23:30,  9.60s/it]dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "[2025-05-24 13:59:37,181] [INFO] [logging.py:107:log_dist] [Rank 0] time (ms) | fwd_microstep: 335.87 | bwd_microstep: 387.34 | bwd_inner_microstep: 386.95 | bwd_allreduce_microstep: 0.07 | step_microstep: 0.09\n",
            "dynamic ViT batch size: 32, images per sample: 32.0, dynamic token length: 2048\n",
            "warning: The size of tensor a (1806) must match the size of tensor b (8192) at non-singleton dimension 0, input_embeds[selected].shape=torch.Size([1806, 2048]), vit_embeds.shape=torch.Size([8192, 2048])\n",
            "W0524 13:59:37.882000 27768 torch/distributed/elastic/agent/server/api.py:719] Received 2 death signal, shutting down workers\n",
            "W0524 13:59:37.883000 27768 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 27789 closing signal SIGINT\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 711, in run\n",
            "    result = self._invoke_run(role)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 870, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 27768 got signal: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 720, in run\n",
            "    self._shutdown(e.sigval)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 372, in _shutdown\n",
            "    self._pcontext.close(death_sig)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 572, in close\n",
            "    self._close(death_sig=death_sig, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 909, in _close\n",
            "    handler.proc.wait(time_to_wait)\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2047, in _wait\n",
            "    time.sleep(delay)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 27768 got signal: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 918, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 260, in launch_agent\n",
            "    result = agent.run()\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/metrics/api.py\", line 137, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 725, in run\n",
            "    self._shutdown()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 372, in _shutdown\n",
            "    self._pcontext.close(death_sig)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 572, in close\n",
            "    self._close(death_sig=death_sig, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 895, in _close\n",
            "    for handler in self.subprocess_handlers.values():\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 27768 got signal: 15\n",
            "[rank0]:[W524 13:59:38.281693860 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=30, addr=[::ffff:127.0.0.1]:58716, remote=[::ffff:127.0.0.1]:29500): failed to recv, got 0 bytes\n",
            "Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:671 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f0e0eab51b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0x6312878 (0x7f0dd70d7878 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #2: c10d::TCPStore::check(std::vector<std::string, std::allocator<std::string> > const&) + 0x354 (0x7f0dd70d3c84 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x383 (0x7f0d9ce19c73 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #4: <unknown function> + 0x145c0 (0x7f0e0eeee5c0 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch.so)\n",
            "frame #5: <unknown function> + 0x94ac3 (0x7f0e173cbac3 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #6: <unknown function> + 0x126850 (0x7f0e1745d850 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n",
            "[rank0]:[W524 13:59:39.596353257 ProcessGroupNCCL.cpp:1680] [PG ID 0 PG GUID 0 Rank 0] Failed to check the \"should dump\" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes\n",
            "Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:671 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f0e0eab51b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0x6312878 (0x7f0dd70d7878 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #2: c10d::TCPStore::check(std::vector<std::string, std::allocator<std::string> > const&) + 0x354 (0x7f0dd70d3c84 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x383 (0x7f0d9ce19c73 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #4: <unknown function> + 0x145c0 (0x7f0e0eeee5c0 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch.so)\n",
            "frame #5: <unknown function> + 0x94ac3 (0x7f0e173cbac3 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #6: <unknown function> + 0x126850 (0x7f0e1745d850 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-341c0fcfb9ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDEEPSPEED_CONFIG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"InternVL/internvl_chat/zero_stage1_config.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CUDA_LAUNCH_BLOCKING=1 TORCH_DISTRIBUTED_DEBUG=DETAIL  torchrun --nproc_per_node=1    \"InternVL/internvl_chat/internvl/train/internvl_chat_finetune.py\"    --model_name_or_path \"OpenGVLab/InternVL2_5-2B\"    --conv_style \"internvl2_5\"    --use_fast_tokenizer False    --output_dir \"/content/drive/MyDrive/deception_detection/internvl2.5-2b-deception-finetuned\"    --meta_path \"/content/drive/MyDrive/deception_detection/meta_train.json\"    --overwrite_output_dir True    --force_image_size 224    --max_dynamic_patch 4    --down_sample_ratio 0.5    --drop_path_rate 0.0    --freeze_llm True    --freeze_mlp True    --freeze_backbone True    --use_llm_lora 16    --vision_select_layer -1    --dataloader_num_workers 2    --fp16 True    --num_train_epochs 1    --per_device_train_batch_size 1    --gradient_accumulation_steps 4    --evaluation_strategy \"no\"    --save_strategy \"steps\"    --save_steps 200    --save_total_limit 1    --learning_rate 4e-5    --weight_decay 0.05    --warmup_ratio 0.03    --lr_scheduler_type \"cosine\"    --logging_steps 1    --max_seq_length 2048    --do_train True    --grad_checkpoint True    --group_by_length True    --dynamic_image_size True    --use_thumbnail True    --ps_version \"v2\"    --deepspeed \"InternVL/internvl_chat/zero_stage1_config.json\"    --report_to \"tensorboard\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}